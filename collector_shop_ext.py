# -*- coding: utf-8 -*-
"""
collector_shop_ext.py - ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  ìˆ˜ì§‘ê¸° (ì‡¼í•‘ê²€ìƒ‰ í™•ì¥ì†Œì¬ ì „ìš© í…ŒìŠ¤íŠ¸ìš©)
"""

import os
import time
import json
import hmac
import base64
import hashlib
import argparse
import sys
import requests
import pandas as pd
from datetime import datetime, date, timedelta
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
import psycopg2.extras
from sqlalchemy.pool import NullPool

load_dotenv(override=True)

API_KEY = (os.getenv("NAVER_API_KEY") or os.getenv("NAVER_ADS_API_KEY") or "").strip()
API_SECRET = (os.getenv("NAVER_API_SECRET") or os.getenv("NAVER_ADS_SECRET") or "").strip()
DB_URL = os.getenv("DATABASE_URL", "").strip()

BASE_URL = "https://api.searchad.naver.com"
TIMEOUT = 60

def log(msg: str):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)

def now_millis() -> str: return str(int(time.time() * 1000))

def sign_path_only(method: str, path: str, timestamp: str, secret: str) -> str:
    msg = f"{timestamp}.{method}.{path}".encode("utf-8")
    dig = hmac.new(secret.encode("utf-8"), msg, hashlib.sha256).digest()
    return base64.b64encode(dig).decode("utf-8")

def request_json(method: str, path: str, customer_id: str, params: dict | None = None) -> tuple:
    url = BASE_URL + path
    ts = now_millis()
    headers = {
        "Content-Type": "application/json; charset=UTF-8",
        "X-Timestamp": ts,
        "X-API-KEY": API_KEY,
        "X-Customer": str(customer_id),
        "X-Signature": sign_path_only(method.upper(), path, ts, API_SECRET),
    }
    for attempt in range(4):
        try:
            r = requests.request(method, url, headers=headers, params=params, timeout=TIMEOUT)
            if r.status_code == 200: return r.json()
            if r.status_code in [429, 500, 502, 503, 504]:
                time.sleep(2 + attempt)
                continue
            return None
        except Exception:
            time.sleep(2 + attempt)
    return None

def get_engine():
    db_url = DB_URL + ("&sslmode=require" if "?" in DB_URL else "?sslmode=require")
    return create_engine(db_url, poolclass=NullPool, future=True)

def process_account(engine, customer_id: str, target_date: date):
    log(f"--- [ {customer_id} ] ì‡¼í•‘ê²€ìƒ‰ í™•ì¥ì†Œì¬ ì „ìš© ìˆ˜ì§‘ ì‹œì‘ ({target_date}) ---")
    
    # 1. ìº í˜ì¸ ì¡°íšŒ í›„ ì‡¼í•‘ê²€ìƒ‰ë§Œ í•„í„°ë§
    camps = request_json("GET", "/ncc/campaigns", customer_id)
    if not camps: return
    shop_camps = [c for c in camps if c.get("campaignTp") == "SHOPPING"]
    log(f"   â–¶ ì‡¼í•‘ê²€ìƒ‰ ìº í˜ì¸ {len(shop_camps)}ê°œ ë°œê²¬")
    
    ad_rows = []
    target_ad_ids = []
    
    # 2. ì‡¼í•‘ê²€ìƒ‰ ìº í˜ì¸ í•˜ìœ„ì˜ ê´‘ê³ ê·¸ë£¹ -> í™•ì¥ì†Œì¬ ì¡°íšŒ
    for c in shop_camps:
        cid = c.get("nccCampaignId")
        groups = request_json("GET", "/ncc/adgroups", customer_id, {"nccCampaignId": cid}) or []
        for g in groups:
            gid = g.get("nccAdgroupId")
            extensions = request_json("GET", "/ncc/ad-extensions", customer_id, {"nccAdgroupId": gid}) or []
            
            for ext in extensions:
                ext_id = ext.get("nccAdExtensionId")
                if ext_id:
                    target_ad_ids.append(ext_id)
                    ext_info = ext.get("adExtension", {}) or ext
                    ext_type = ext.get("extensionType", "")
                    
                    # ì¶”ê°€í™ë³´ë¬¸êµ¬, ì„œë¸Œë§í¬ ë“±ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    ext_text = ext_info.get("promoText") or ext_info.get("addPromoText") or ext_info.get("subLinkName") or ext_info.get("pcText") or str(ext_type)
                    ext_title = f"[í™•ì¥ì†Œì¬] {ext_type}"
                    
                    ad_rows.append({
                        "customer_id": str(customer_id), "ad_id": str(ext_id), "adgroup_id": str(gid),
                        "ad_name": ext_text, "status": ext.get("status"), "ad_title": ext_title, 
                        "ad_desc": ext_text, "pc_landing_url": ext_info.get("pcLandingUrl", ""), 
                        "mobile_landing_url": ext_info.get("mobileLandingUrl", ""),
                        "creative_text": f"{ext_title} | {ext_text}"[:500]
                    })

    # 3. DB ì €ì¥ (dim_ad)
    if ad_rows:
        df = pd.DataFrame(ad_rows).drop_duplicates(subset=["customer_id", "ad_id"], keep='last')
        tuples = list(df.itertuples(index=False, name=None))
        cols = '", "'.join(df.columns)
        update_clause = ", ".join([f'"{c}"=EXCLUDED."{c}"' for c in df.columns if c not in ["customer_id", "ad_id"]])
        sql = f'INSERT INTO dim_ad ("{cols}") VALUES %s ON CONFLICT (customer_id, ad_id) DO UPDATE SET {update_clause}'
        
        try:
            raw_conn = engine.raw_connection()
            cur = raw_conn.cursor()
            psycopg2.extras.execute_values(cur, sql, tuples, page_size=2000)
            raw_conn.commit()
            log(f"   â–¶ ì‡¼í•‘ê²€ìƒ‰ í™•ì¥ì†Œì¬ {len(ad_rows)}ê°œ dim_ad ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            log(f"DB ì €ì¥ ì˜¤ë¥˜: {e}")
            if raw_conn: raw_conn.rollback()

    # 4. ì¡°íšŒëœ í™•ì¥ì†Œì¬ë“¤ì˜ í†µê³„ ë°ì´í„° ìˆ˜ì§‘
    if target_ad_ids:
        log(f"   â–¶ í™•ì¥ì†Œì¬ {len(target_ad_ids)}ê°œ stats(í†µê³„) ì¡°íšŒ ì¤‘...")
        d_str = target_date.strftime("%Y-%m-%d")
        fields = json.dumps(["impCnt", "clkCnt", "salesAmt", "ccnt", "convAmt"], separators=(',', ':'))
        time_range = json.dumps({"since": d_str, "until": d_str}, separators=(',', ':'))
        
        raw_stats = []
        for i in range(0, len(target_ad_ids), 50):
            chunk = target_ad_ids[i:i+50]
            params = {"ids": ",".join(chunk), "fields": fields, "timeRange": time_range}
            res = request_json("GET", "/stats", customer_id, params=params)
            if res and "data" in res: raw_stats.extend(res["data"])

        # 5. DB ì €ì¥ (fact_ad_daily)
        fact_rows = []
        for r in raw_stats:
            cost = int(round(float(r.get("salesAmt", 0) or 0) * 1.1))
            sales = int(float(r.get("convAmt", 0) or 0))
            fact_rows.append({
                "dt": target_date, "customer_id": str(customer_id), "ad_id": str(r.get("id")),
                "imp": int(r.get("impCnt", 0) or 0), "clk": int(r.get("clkCnt", 0) or 0), 
                "cost": cost, "conv": float(r.get("ccnt", 0) or 0), "sales": sales,
                "roas": (sales / cost * 100.0) if cost > 0 else 0.0
            })
            
        if fact_rows:
            df_fact = pd.DataFrame(fact_rows)
            try:
                with engine.begin() as conn:
                    conn.execute(text("DELETE FROM fact_ad_daily WHERE customer_id=:cid AND dt=:dt AND ad_id IN :ids"), 
                                 {"cid": str(customer_id), "dt": target_date, "ids": tuple(target_ad_ids)})
            except Exception: pass
            
            tuples_f = list(df_fact.itertuples(index=False, name=None))
            # âœ¨ SyntaxError í•´ê²°: ë¬¸ìì—´ í•©ì¹˜ëŠ” ë¶€ë¶„ì„ ë°–ìœ¼ë¡œ ë¹¼ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            col_names = '", "'.join(df_fact.columns)
            sql_f = f'INSERT INTO fact_ad_daily ("{col_names}") VALUES %s'
            try:
                raw_conn = engine.raw_connection()
                cur = raw_conn.cursor()
                psycopg2.extras.execute_values(cur, sql_f, tuples_f, page_size=2000)
                raw_conn.commit()
                log(f"   â–¶ í™•ì¥ì†Œì¬ í†µê³„ {len(fact_rows)}ê±´ fact_ad_daily ì ì¬ ì™„ë£Œ")
            except Exception as e: log(f"í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")
        else:
            log("   â–¶ ì¡°íšŒëœ ì‡¼í•‘ê²€ìƒ‰ í™•ì¥ì†Œì¬ í†µê³„ ë°ì´í„°ê°€ 0ê±´ì…ë‹ˆë‹¤.")

def main():
    engine = get_engine()
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", type=str, default="")
    args = parser.parse_args()
    
    target_date = datetime.strptime(args.date, "%Y-%m-%d").date() if args.date else date.today() - timedelta(days=1)
    
    print("\n" + "="*50, flush=True)
    print(f"ğŸ›ï¸ ì‡¼í•‘ê²€ìƒ‰ í™•ì¥ì†Œì¬ ì „ìš© í…ŒìŠ¤íŠ¸ ìˆ˜ì§‘ê¸° [ë‚ ì§œ: {target_date}]", flush=True)
    print("="*50 + "\n", flush=True)

    accounts = []
    try:
        with engine.connect() as conn:
            accounts = [str(r[0]) for r in conn.execute(text("SELECT DISTINCT customer_id FROM dim_account_meta"))]
    except Exception: pass
    
    if not accounts:
        cid = os.getenv("CUSTOMER_ID")
        if cid: accounts = [cid]

    for acc in accounts:
        process_account(engine, acc, target_date)

if __name__ == "__main__":
    main()
